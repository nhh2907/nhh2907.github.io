<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.3.0" /><meta property="og:title" content="[Recsys] Collaborative Filtering Model" /><meta name="author" content="nhh2907" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="ğŸ’¡ ì „ì²´ ê·¸ë¦¼ì„ ë³´ì—¬ì£¼ëŠ” ë§ˆì¸ë“œë§µ" /><meta property="og:description" content="ğŸ’¡ ì „ì²´ ê·¸ë¦¼ì„ ë³´ì—¬ì£¼ëŠ” ë§ˆì¸ë“œë§µ" /><link rel="canonical" href="https://nhh2907.github.io/posts/Collaborative_Filtering_Model/" /><meta property="og:url" content="https://nhh2907.github.io/posts/Collaborative_Filtering_Model/" /><meta property="og:site_name" content="HYUNHO NOH" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-03-22T23:45:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[Recsys] Collaborative Filtering Model" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@nhh2907" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"nhh2907"},"dateModified":"2023-03-30T22:05:55+09:00","datePublished":"2023-03-22T23:45:00+09:00","description":"ğŸ’¡ ì „ì²´ ê·¸ë¦¼ì„ ë³´ì—¬ì£¼ëŠ” ë§ˆì¸ë“œë§µ","headline":"[Recsys] Collaborative Filtering Model","mainEntityOfPage":{"@type":"WebPage","@id":"https://nhh2907.github.io/posts/Collaborative_Filtering_Model/"},"url":"https://nhh2907.github.io/posts/Collaborative_Filtering_Model/"}</script><title>[Recsys] Collaborative Filtering Model | HYUNHO NOH</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-CFRW971PP6"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-CFRW971PP6'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/profile/howl_fire.JPG" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">HYUNHO NOH</a></div><div class="site-subtitle font-italic">Data Scientist <br> ML, NLP, RecommenderSystem</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/portfolio/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>PORTFOILO</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/nhh2907" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/nhh2907" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['nhh2907','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG â€º <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>[Recsys] Collaborative Filtering Model</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[Recsys] Collaborative Filtering Model</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Mar 22, 2023, 11:45 PM +0900" > Mar 22 <i class="unloaded">2023-03-22T23:45:00+09:00</i> </span> by <span class="author"> nhh2907 </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Thu, Mar 30, 2023, 10:05 PM +0900" > Mar 30 <i class="unloaded">2023-03-30T22:05:55+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2171 words">12 min</span></div></div><div class="post-content"><aside> ğŸ’¡ ì „ì²´ ê·¸ë¦¼ì„ ë³´ì—¬ì£¼ëŠ” ë§ˆì¸ë“œë§µ [Matrix Factorization - Summary](https://github.com/nhh2907/nhh2907.github.io/blob/main/assets/img/etc/recsys/2023-03-22-Collaborative_Filtering_Model/Matrix_Factorization_Summary.pdf)</aside><h1 id="ë°ì´í„°-ì¢…ë¥˜ì—-ë”°ë¥¸-ì¶”ì²œì‹œìŠ¤í…œ-ëª¨ë¸-ì¢…ë¥˜">ë°ì´í„° ì¢…ë¥˜ì— ë”°ë¥¸ ì¶”ì²œì‹œìŠ¤í…œ ëª¨ë¸ ì¢…ë¥˜</h1><ol><li><p><span style="color:coral"><strong>User-Item Interaction</strong></span> â†’ Collaborative Filtering Methods ì‚¬ìš©</p><p>ex) ratings or buying behavior</p><li><p><strong>Attribute Information</strong> about the users and items â†’ Content-based Methods ì‚¬ìš©</p><p>ex) textual profiles or relevant keywords, a single(not all) userâ€™s rating</p></ol><h1 id="ì •ì˜">ì •ì˜</h1><p>Collaborative filtering models use <strong>the collaborative power of the ratings provided by multiple users</strong> to make recommendations</p><p>To address some of the limitations of content-based filtering, collaborative filtering usesÂ <strong><em>similarities between users and items simultaneously</em></strong>Â to provide recommendations. This allows for serendipitous recommendations; that is, collaborative filtering models <strong>can recommend an item to user A based on the interests of a similar user B</strong>. Furthermore, the embeddings can be learned automatically, without relying on hand-engineering of features</p><h1 id="explicit-implicit">Explicit, Implicit</h1><h3 id="explicit"><strong>Explicit</strong></h3><p>Users specify <strong>how much they liked</strong> a particular movie by providing a numerical rating</p><h3 id="implicit-"><strong>Implicit :</strong></h3><p>If a user <strong>watches(í–‰ë™)</strong> a movie, the system infers that the user is interested</p><p>Customer preferences are derived from their <strong>activities</strong> rather than their explicitly specified ratings</p><p>When a customer <strong>buys(í–‰ë™)</strong> an item, it can be viewed as a preference for the item. However, the act of not buying an item from a large universe of possibilities does not always indicate a dislike</p><h1 id="ë‹¨ì ">ë‹¨ì </h1><ol><li><p>The underlying <strong>ratings(or feedback) matrices are sparse</strong></p><p>In the movie cases, most users would have viewed only a small fraction of the large universe of available movies</p><p>â†’ í•´ê²°ì±…:</p><ul><li><a href="https://docs.scipy.org/doc/">CSR Matrix</a> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/etc/recsys/2023-03-22-Collaborative_Filtering_Model/01.CSR_matrix.png" alt="CSR_Matrix" /><li><a href="https://matteding.github.io/2019/04/25/sparse-matrices/#coordinate-matrix">Linked List Matrix(LIL)</a></ul><li>Cannot handle fresh items<li>Hard to include side features for query/item</ol><h1 id="collaborative-filteringì˜-ë‘-ê°€ì§€-ë°©ì‹">Collaborative Filteringì˜ ë‘ ê°€ì§€ ë°©ì‹</h1><h2 id="memory-based-collaborative-filtering">Memory-based Collaborative Filtering</h2><p>â€» <strong>Nearest neighborhood-based(ìµœê·¼ì ‘ì´ì›ƒê¸°ë°˜)</strong> Collaborative Filteringì´ë¼ê³ ë„ í•¨</p><p>These algorithms are based on the fact that <strong>similar users display similar patterns of rating behavior</strong> and <strong>similar items receive similar ratings</strong></p><p>â†’ Target Userê°€ ì•„ì§ í‰ê°€í•˜ì§€ ì•Šì€ ì•„ì´í…œì„ Target Userì™€ ìœ ì‚¬í•œ Userì§‘ë‹¨ë“¤ì˜ í‰ê°€ì˜ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ëª©í‘œ!</p><h3 id="methods">Methods</h3><ol><li><p>User-based collaborative filtering ë°©ë²•</p><p>í•œ ì•„ì´í…œì— ëŒ€í•œ ì¶”ì²œ ì •ë„ë¥¼ ì¸¡ì •í•˜ë ¤ë©´ <strong>í•´ë‹¹ ì•„ì´í…œì— ëŒ€í•´ í‰ì ì„ ë‚´ë ¸ë˜ ìœ ì €ë“¤ ì „ì²´ ì¤‘ì—ì„œ ë‚˜ì™€ ìœ ì‚¬ë„ê°€ ë†’ì€ ìœ ì €ë“¤ë§Œ ì¶”ë ¤ í•´ë‹¹ ì•„ì´í…œì„ ì–´ë–»ê²Œ í‰ê°€í•˜ê³  ìˆëŠ”ì§€ í™•ì¸</strong>í•˜ëŠ” ë°©ë²•</p><p>The ratings provided by like-minded user<strong>s</strong> of a target user A are used in order to make the recommendations for user A</p><p>Similarity functions are computed between the rows of the ratings matrix to discover similar users</p><div class="table-wrapper"><table><thead><tr><th>Â <th><span style="color:coral">ItemA</span><th><span style="color:coral">ItemB</span><th><span style="color:coral">ItemC</span><th>ItemD<th>ItemE<tbody><tr><td><span style="color:coral">User1</span><td><span style="color:coral">3</span><td><span style="color:coral">4</span><td><span style="color:coral">4</span><td>Â <td>1<tr><td><span style="color:coral">User2</span><td><span style="color:coral">4</span><td><span style="color:coral">4</span><td><span style="color:coral">4</span><td>3<td>Â <tr><td>User3<td>1<td>1<td>2<td>5<td>Â </table></div><p>â€» ì£¼í™©ìƒ‰ : ìœ ì‚¬ë„ê°€ ë†’ìŒ</p><p>â€» í…Œì´ë¸” í•´ì„ : User1ê³¼ User2ëŠ” ItemA, B, Cê¹Œì§€ í‰ì  ìœ ì‚¬ë„ê°€ ë†’ë‹¤</p><li><p>Item-based collaborative filtering ë°©ë²•</p><p>In order to make recommendations for target item A, the first step is to determine a set S of items, which are most similar to item A. Then, in order to predict the rating of any particular user4 for item A, the ratings in set S, which are specified by user4, are determined. The weighted average of these ratings is used to compute the predicted rating of user A for item B</p><p>Similarity functions are computed between the columns of the ratings matrix to discover similar items</p><p>When such methods are applied to the transpose of the ratings matrix, they are referred to as item-based neighborhood models</p><div class="table-wrapper"><table><thead><tr><th>Â <th><span style="color:coral">User1</span><th><span style="color:coral">User2</span><th><span style="color:coral">User3</span><th>User4<th>User5<tbody><tr><td><span style="color:coral">ItemA</span><td><span style="color:coral">5</span><td><span style="color:coral">4</span><td><span style="color:coral">4</span><td>Â <td>5<tr><td><span style="color:coral">ItemB</span><td><span style="color:coral">4</span><td><span style="color:coral">4</span><td><span style="color:coral">4</span><td>5<td>Â <tr><td>ItemC<td>1<td>1<td>2<td>3<td>Â </table></div><p>â€» ì£¼í™©ìƒ‰ : ìœ ì‚¬ë„ê°€ ë†’ìŒ</p></ol><h3 id="distinction-between-user-based-and-item-based">Distinction Between User-based and Item-based</h3><p>The ratings in user-based CF are predicted using the ratings of neighboring users, whereas the ratings in item-based CF are predicted using the userâ€™s <em>own</em> ratings on neighboring (i.e., closely related) <em>items</em>.</p><p>In the user-based CF case, neighborhoods are defined by <strong>similarities among users (rows of ratings matrix)</strong>, whereas in the item-based C case, neighborhoods are defined by <strong>similarities among items (columns of ratings matrix)</strong></p><h3 id="strengths-and-weaknesses-of-neighborhood-based-methods">Strengths and Weaknesses of Neighborhood-Based Methods</h3><ol><li><strong>Advantages</strong><ul><li><p>Simplicity and intuitive approach.</p><p>It is often easy to justify why a specific item is recommended, and the interpretability of item-based methods is particularly notable</p><li><p>Relatively stable with the addition of new items and users</p></ul><li><strong>Disadvantage</strong><ul><li>Least O(m2) time and space.<li><p>Limited coverage because of sparsity</p><p>For example, if none of Johnâ€™s nearest neighbors have rated Terminator, it is not possible to provide a rating prediction of Terminator for John. On the other hand, we care only about the top-k items of John in most recommendation settings. If none of Johnâ€™s nearest neighbors have rated Terminator, then it might be evidence that this movie is not a good recommendation for John. Sparsity also creates challenges for robust similarity computation when the number of mutually rated items between two users is small.</p></ul></ol><h2 id="model-based-collaborative-filtering">Model-based Collaborative Filtering</h2><p>In model-based methods, machine learning and data mining methods are used in the context of predictive models. In cases where the model is parameterized, the parameters of this model are learned within the context of an optimization framework. Some examples of such model-based methods include decision trees, rule-based models, Bayesian methods and latent factor models. Many of these methods, such as latent factor models, have a high level of coverage even for sparse ratings matrices</p><h3 id="data-matrix">Data Matrix</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/etc/recsys/2023-03-22-Collaborative_Filtering_Model/02.Data_Matrix.png" alt="Data_Matrix" /></p><ol><li><p>Data Classification problem</p><p>we have an m Ã— n matrix, in which the first (n âˆ’ 1) columns are feature variables (or independent variables), and the last (i.e., nth) column is the class variable (or dependent variable). All entries in the first (n âˆ’ 1) columns are fully specified, whereas only a subset of the entries in the nth column is specified. Therefore, a subset of the rows in the matrix is fully specified, and these rows are referred to as the training data. The remaining rows are referred to as the test data. The values of the missing entries need to be learned for the test data. This scenario is illustrated in Figure 3.1(a), where the shaded values represent missing entries in the matrix.</p><p>Columns represent features, and rows represent data instances</p><li><p>Collaborative Filtering Problem</p><p>Any entry in the ratings matrix may be missing, as illustrated by the shaded entries in Figure 3.1(b). Thus, it can be clearly seen that the matrix completion problem is a generalization of the classification (or regression modeling) problem</p><p>The specified (observed) entries to be the training data, and the unspecified (missing) entries to be the test data.</p></ol><h3 id="advantages">Advantages</h3><ol><li><p><strong>Space-efficiency</strong>:</p><p>Typically, the size of the learned model is much smaller than the original ratings matrix. Thus, the space requirements are often quite low. On the other hand, a user-based neighborhood method might have O(m2) space complexity, where m is the number of users. An item-based method will have O(n2) space complexity.</p><li><p><strong>Training speed and prediction speed</strong>:</p><p>One problem with neighborhood-based methods is that the pre-processing stage is quadratic in either the number of users or the number of items. Model-based systems are usually much faster in the preprocessing phase of constructing the trained model. In most cases, the compact and summarized model can be used to make predictions efficiently.</p><li><p><strong>Avoiding overfitting</strong>:</p><p>Overfitting is a serious problem in many machine learning algorithms, in which the prediction is overly influenced by random artifacts in the data. This problem is also encountered in classification and regression models. The summarization approach of model-based methods can often help in avoiding overfitting. Furthermore, regularization methods can be used to make these models robust.</p></ol><h3 id="types-for-model-based-cf">Types for Model-based CF</h3><ul><li>Decision and Regression Tree to Collaborative Filtering<li>Rule-based Collaborative Filtering<li>â€¦<li><strong>Latent Factor Models</strong><li>â€¦</ul><p>â†’ ë‹¤ìŒì€ Model-based CF ì¤‘ <strong>Latent Factor Models</strong>ì— ëŒ€í•´ ì„¤ëª…í•¨</p><h1 id="latent-factor-models">Latent Factor Models</h1><p>The goal is to use <strong>dimensionality reduction</strong> methods to directly estimate the data matrix in one shot</p><h2 id="dimensionality-reduction">D<strong>imensionality</strong> Reduction</h2><p>These models leverage well-known <strong>dimensionality reduction</strong> methods to fill in the missing entries. Dimensionality reduction methods are used commonly in other areas of data analytics to represent the underlying data in a small number of dimensions. <strong>The key idea</strong> in dimensionality reduction methods is that the reduced, rotated, and completely specified representation can be robustly estimated from an incomplete data matrix. Once the completely specified representation has been obtained, one can rotate it back to the original axis system in order to obtain the fully specified representation. Under the covers, dimensionality reduction methods<span style="color:coral"> <strong>leverage the row and column correlations</strong></span> to create the fully specified and reduced representation. For example, user-based neighborhood methods leverage user-wise correlations, whereas item-based neighborhood methods leverage item-wise correlations</p><h2 id="intuition-for-understanding-latent-factor-model">Intuition for understanding Latent Factor Model</h2><h3 id="1-geometric-intuition">(1) Geometric Intuition</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/etc/recsys/2023-03-22-Collaborative_Filtering_Model/03.Geometric_intuition.png" alt="Geometric Intuition" /></p><p><span style="background-color:#2471A3">â†’ ì´í›„ ì„¤ëª…ì€ ì´í•´í•  ìˆ˜ ì—†ì—ˆìŒ. ë‹¤ìŒì— ë‹¤ì‹œ í™•ì¸í•´ë´ì•¼ê² ë‹¤</span></p><h3 id="2low-rank-intuition">(2)Low-Rank Intuition</h3>\[R = UV^T\]<ul><li>$U=m \times k$<li>$V = n \times k$<li>The rank of both row space and the column space of $R$ is $k$</ul><p><span style="background-color:#2471A3">â†’ ì´í›„ ì„¤ëª…ì€ ì´í•´í•  ìˆ˜ ì—†ì—ˆìŒ. ë‹¤ìŒì— ë‹¤ì‹œ í™•ì¸í•´ë´ì•¼ê² ë‹¤</span></p><h2 id="matrix-factorizationmf">Matrix Factorization(MF)</h2><p>Matrix factorization methods provide a neat way to <strong>leverage all row and column correlations in one shot</strong> to estimate the entire data matrix</p><p>Most dimensionality reduction methods can also be expressed as matrix factorizations</p><p>The goal of matrix factorization is to find the optimal feature vectors that minimize the difference between the estimated ratings and the actual ratings</p><h3 id="basic-principles-of-mf">Basic Principles of MF</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/etc/recsys/2023-03-22-Collaborative_Filtering_Model/04.MF1.png" alt="MF1" /></p><ol><li>Formula</ol><p>$ R \approx UV^T $</p><ul><li> \[A \in R^{\ m \times n}\]<p>, where $m$ is the number of users(or queries) and $n$ is the number of items</p><li><p>Latent Vector/Component: Each column of $U$ (or $V$)</p><p>A latent vector may often be an arbitrary vector of positive and negative values and it becomes difficult to give it a semantic interpretation. However, it does represent a <strong>dominant correlation pattern</strong> in the ratings matrix</p><li>Latent Factor : Each row of $U$ (or $V$)<ul><li><p>User Factor: Each row $\bar{u_i}$ of $U$</p><p>It contains $k$ entries corresponding to the <strong>affinity</strong> of user $i$ towards the $k$ concepts in the ratings matrix</p><li><p>Item Factor : Each row $\bar{v_i}$ of $V$</p><p>It represents the <strong>affinity</strong> of the $i$th item towards these $k$ concepts</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/etc/recsys/2023-03-22-Collaborative_Filtering_Model/05,MF2.png" alt="MF2" /></p></ul></ul><ol><li>Each Rating Value($r_{ij}$)</ol>\[r_{ij} \approx \bar{u_i} \ \cdot \ \bar{v_i}\]<ul><li>$\bar{u_i}= (u_{i1}\dots u_{ik})$<li>$\bar{v_j}= (v_{j1} \dots v_{jk})$</ul>\[r_{ij} \approx \Sum^k_{s=1}u_{is} \ \cdot \ v_{js}\] \[= \Sum^k_{s=1}(\text{Affinity of user i to concept s}) \ \times (\text{Affinity of item j to concept s})\]<h3 id="complexity">Complexity</h3><p>Matrix factorization typically gives a more compact representation than learning the full matrix. The full matrix has $O(nm)$entries, while the embedding matrices $U, V$ have $O((n+m)d)$ entries, where the embedding dimension $d$ is typically much smaller than $m$ and $n$</p><p>As a result, matrix factorization finds latent structure in the data, assuming that observations lie close to a low-dimensional subspace. In the preceding example, the values of n, m, and d are so low that the advantage is negligible. In real-world recommendation systems, however, matrix factorization can be significantly more compact than learning the full matrix.</p><h3 id="advantage-and-disadvantage-of-mf">Advantage and Disadvantage of MF</h3><p><strong>Advantage</strong></p><ul><li><p>Handle sparse and incomplete data</p><p>MF can fill in the missing values and predict ratings for unseen items or users</p><li><p>Reduce the dimensionality and complexity of the data</p><p>MF can compress a large matrix into smaller matrices that capture the essential information and reduce the noise</p><li><p>Discover latent features and patterns that are not obvious or explicit in the data</p><p>MF can reveal hidden similarities and preferences among users and items, which can enhance the quality and diversity of the recommendations</p></ul><p><strong>Disadvantage</strong></p><ul><li><p>Overfitting and underfitting</p><p>To avoid these problems, matrix factorization needs to balance the trade-off between fitting the data and regularizing the feature vectors</p><li>Sensitive to the choice of parameters<li><p>Limited by the linearity and independence assumptions</p><p>Matrix factorization assumes that the rating is a linear combination of the features, and that the features are independent of each other. However, in some cases, the rating may depend on nonlinear or interactive features, or on external factors such as context, time, or social influence. To address these limitations, matrix factorization may need to incorporate additional information or techniques, such as nonlinear functions, feature engineering, or hybrid models</p></ul><h1 id="reference">Reference</h1><ul><li><a href="https://www.amazon.com/Recommender-Systems-Textbook-Charu-Aggarwal/dp/3319296574/ref=sr_1_3?crid=HFBJ4WHDJN7&amp;keywords=Recommender+Systems&amp;qid=1679456254&amp;sprefix=%2Caps%2C254&amp;sr=8-3">Recommender Systems(Charu C. Aggarwal)</a><li><a href="https://developers.google.com/machine-learning/recommendation/collaborative/basics">Collaborative Filtering - Google</a><li><a href="https://developers.google.com/machine-learning/recommendation/collaborative/matrix">Matrix Factorization - Google</a><li><a href="https://www.linkedin.com/advice/0/what-some-advantages-disadvantages-using-matrix-factorization">MF Pros and Cons - Linkedin</a><li><a href="https://ieeexplore.ieee.org/document/5197422">Matrix Factorization Techniques for Recommender Systems - Papers</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ai/'>AI</a>, <a href='/categories/recommender-system/'>Recommender System</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/ml/" class="post-tag no-text-decoration">ML</a> <a href="/tags/recommendersystem/" class="post-tag no-text-decoration">RecommenderSystem</a> <a href="/tags/matrix-factorization/" class="post-tag no-text-decoration">Matrix Factorization</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[Recsys] Collaborative Filtering Model - HYUNHO NOH&url=https://nhh2907.github.io/posts/Collaborative_Filtering_Model/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[Recsys] Collaborative Filtering Model - HYUNHO NOH&u=https://nhh2907.github.io/posts/Collaborative_Filtering_Model/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[Recsys] Collaborative Filtering Model - HYUNHO NOH&url=https://nhh2907.github.io/posts/Collaborative_Filtering_Model/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Conditional_Probability_Bayes_Theorem/">[Statistics] 01. ì¡°ê±´ë¶€í™•ë¥ ê³¼ Bayes ì •ë¦¬</a><li><a href="/posts/Collaborative_Filtering_Model/">[Recsys] Collaborative Filtering Model</a><li><a href="/posts/Supervised_Unsupervised_Machine_Learning/">[ML] 01. Supervised vs Unsupervised Machine Learning</a><li><a href="/posts/Markdown_%EC%84%A4%EB%AA%85/">Markdown ì„¤ëª…</a><li><a href="/posts/jekyll_Chirpy_%EC%84%A4%EC%B9%98_%EC%A0%81%EC%9A%A9/">Jekyll ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ ì„¤ì •</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/coursera/">Coursera</a> <a class="post-tag" href="/tags/jekyll/">Jekyll</a> <a class="post-tag" href="/tags/kocw/">KOCW</a> <a class="post-tag" href="/tags/language/">Language</a> <a class="post-tag" href="/tags/matrix-factorization/">Matrix Factorization</a> <a class="post-tag" href="/tags/recommendersystem/">RecommenderSystem</a> <a class="post-tag" href="/tags/%EC%9D%B4%EC%83%81%ED%99%94/">ì´ìƒí™”</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Supervised_Unsupervised_Machine_Learning/"><div class="card-body"> <span class="timeago small" > Mar 19 <i class="unloaded">2023-03-19T15:12:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ML] 01. Supervised vs Unsupervised Machine Learning</h3><div class="text-muted small"><p> Tags: Week 1 : Introduction to Machine Learning What Is Machine Learning? The field of study that gives computers the ability to learn without being explicitly programmed Arthur Samuel...</p></div></div></a></div><div class="card"> <a href="/posts/Regression_Model/"><div class="card-body"> <span class="timeago small" > Mar 26 <i class="unloaded">2023-03-26T00:12:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ML] 02. Regression Model</h3><div class="text-muted small"><p> Tags: Week 1 : Introduction to Machine Learning C1_W1_Lab03_Cost_function_Soln.ipynb Regression ì •ì˜ Regression is to predict numbers Any supervised learning model that predicts a number such a...</p></div></div></a></div><div class="card"> <a href="/posts/Conditional_Probability_Bayes_Theorem/"><div class="card-body"> <span class="timeago small" > Apr 1 <i class="unloaded">2023-04-01T09:12:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[Statistics] 01. ì¡°ê±´ë¶€í™•ë¥ ê³¼ Bayes ì •ë¦¬</h3><div class="text-muted small"><p> ìš©ì–´ í‘œë³¸ê³µê°„(Sample Space) ëª¨ì§‘ë‹¨ì— ëŒ€í•˜ì—¬ ëª¨ë“  ê°œì²´ì˜ ì†ì„±ì„ ì¡°ì‚¬í•˜ê¸° ì „ì—ëŠ” ì–´ë–¤ ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤ê³  í™•ì‹¤íˆ ë§í•  ìˆ˜ ì—†ë‹¤. ê·¸ëŸ¬ë‚˜ ì†ì„±ì˜ ê°€ëŠ¥í•œ ëª¨ë“  ê²°ê³¼ë¥¼ ë‚˜ì—´í•˜ê±°ë‚˜ í‘œí˜„í•˜ëŠ” ê²ƒì€ ê°€ëŠ¥í•˜ë‹¤. ì´ë•Œ ê°€ëŠ¥í•œ ì†ì„±ì˜ ëª¨ë“  ê²°ê³¼ë¥¼ í‘œë³¸ê³µê°„(ì§‘í•©) ë˜ëŠ” ê°„ë‹¨íˆ ê³µê°„ì´ë¼ í•˜ê³ Â $S$ï»¿, $\Omega$ ë“±ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤. í‘œë³¸ê³µê°„ì€ ì‚¬ê±´ê³µê°„ì´ë¼...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Supervised_Unsupervised_Machine_Learning/" class="btn btn-outline-primary" prompt="Older"><p>[ML] 01. Supervised vs Unsupervised Machine Learning</p></a> <a href="/posts/Regression_Model/" class="btn btn-outline-primary" prompt="Newer"><p>[ML] 02. Regression Model</p></a></div><script src="https://utteranc.es/client.js" repo="Han-Joon-Hyeok/Han-Joon-Hyeok.github.io" issue-term="pathname" label="Comments" theme="preferred-color-scheme" crossorigin="anonymous" async> </script></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> Â© 2023 <a href="https://github.com/nhh2907">Hyunho Noh</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/coursera/">Coursera</a> <a class="post-tag" href="/tags/jekyll/">Jekyll</a> <a class="post-tag" href="/tags/kocw/">KOCW</a> <a class="post-tag" href="/tags/language/">Language</a> <a class="post-tag" href="/tags/matrix-factorization/">Matrix Factorization</a> <a class="post-tag" href="/tags/recommendersystem/">RecommenderSystem</a> <a class="post-tag" href="/tags/%EC%9D%B4%EC%83%81%ED%99%94/">ì´ìƒí™”</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://nhh2907.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
